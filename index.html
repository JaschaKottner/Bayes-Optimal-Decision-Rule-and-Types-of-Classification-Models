<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.32">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Bayes Optimal Decision Rule and Types of Classification Models</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="GNB_files/libs/clipboard/clipboard.min.js"></script>
<script src="GNB_files/libs/quarto-html/quarto.js" type="module"></script>
<script src="GNB_files/libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="GNB_files/libs/quarto-html/popper.min.js"></script>
<script src="GNB_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="GNB_files/libs/quarto-html/anchor.min.js"></script>
<link href="GNB_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="GNB_files/libs/quarto-html/quarto-syntax-highlighting-37eea08aefeeee20ff55810ff984fec1.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="GNB_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="GNB_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="GNB_files/libs/bootstrap/bootstrap-81267100e462c21b3d6c0d5bf76a3417.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<link href="GNB_files/libs/htmltools-fill-0.5.8/fill.css" rel="stylesheet">
<script src="GNB_files/libs/htmlwidgets-1.6.4/htmlwidgets.js"></script>
<script src="GNB_files/libs/viz-1.8.2/viz.js"></script>
<link href="GNB_files/libs/DiagrammeR-styles-0.2/styles.css" rel="stylesheet">
<script src="GNB_files/libs/grViz-binding-1.0.11/grViz.js"></script>

  <script>window.backupDefine = window.define; window.define = undefined;</script><script src="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.js"></script>
  <script>document.addEventListener("DOMContentLoaded", function () {
 var mathElements = document.getElementsByClassName("math");
 var macros = [];
 for (var i = 0; i < mathElements.length; i++) {
  var texText = mathElements[i].firstChild;
  if (mathElements[i].tagName == "SPAN") {
   katex.render(texText.data, mathElements[i], {
    displayMode: mathElements[i].classList.contains('display'),
    throwOnError: false,
    macros: macros,
    fleqn: false
   });
}}});
  </script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css">

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="quarto-light">

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article toc-left">
<div id="quarto-sidebar-toc-left" class="sidebar toc-left">
  <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#introduction" id="toc-introduction" class="nav-link active" data-scroll-target="#introduction">Introduction</a>
  <ul class="collapse">
  <li><a href="#topics" id="toc-topics" class="nav-link" data-scroll-target="#topics">Topics</a></li>
  <li><a href="#orientation-map" id="toc-orientation-map" class="nav-link" data-scroll-target="#orientation-map">Orientation Map</a></li>
  </ul></li>
  <li><a href="#key-concepts" id="toc-key-concepts" class="nav-link" data-scroll-target="#key-concepts">Key Concepts</a>
  <ul class="collapse">
  <li><a href="#marginalization" id="toc-marginalization" class="nav-link" data-scroll-target="#marginalization">Marginalization</a></li>
  <li><a href="#conditional-density" id="toc-conditional-density" class="nav-link" data-scroll-target="#conditional-density">Conditional Density</a></li>
  <li><a href="#conditional-expectation" id="toc-conditional-expectation" class="nav-link" data-scroll-target="#conditional-expectation">Conditional Expectation</a></li>
  </ul></li>
  <li><a href="#proofs" id="toc-proofs" class="nav-link" data-scroll-target="#proofs">Proofs</a>
  <ul class="collapse">
  <li><a href="#tower-property" id="toc-tower-property" class="nav-link" data-scroll-target="#tower-property">Tower Property</a></li>
  <li><a href="#mathbbeùüô_ymathbbpy" id="toc-mathbbeùüô_ymathbbpy" class="nav-link" data-scroll-target="#mathbbeùüô_ymathbbpy"><span class="math inline">\mathbb{E}[ùüô_Y]=\mathbb{P}(Y)</span></a></li>
  <li><a href="#mathbbeùüô_y-vert-xmathbbpy-vert-x" id="toc-mathbbeùüô_y-vert-xmathbbpy-vert-x" class="nav-link" data-scroll-target="#mathbbeùüô_y-vert-xmathbbpy-vert-x"><span class="math inline">\mathbb{E}[ùüô_Y \vert X]=\mathbb{P}(Y \vert X)</span></a></li>
  <li><a href="#optimal-classifier" id="toc-optimal-classifier" class="nav-link" data-scroll-target="#optimal-classifier">Optimal Classifier</a></li>
  </ul></li>
  <li><a href="#model-types" id="toc-model-types" class="nav-link" data-scroll-target="#model-types">Model Types</a>
  <ul class="collapse">
  <li><a href="#pros-and-cons" id="toc-pros-and-cons" class="nav-link" data-scroll-target="#pros-and-cons">Pros and cons</a></li>
  <li><a href="#some-models-listed" id="toc-some-models-listed" class="nav-link" data-scroll-target="#some-models-listed">Some models listed</a></li>
  </ul></li>
  <li><a href="#classification-via-bayes-rule" id="toc-classification-via-bayes-rule" class="nav-link" data-scroll-target="#classification-via-bayes-rule">Classification via Bayes‚Äô Rule</a></li>
  <li><a href="#naive-bayes" id="toc-naive-bayes" class="nav-link" data-scroll-target="#naive-bayes">Naive Bayes</a></li>
  <li><a href="#application" id="toc-application" class="nav-link" data-scroll-target="#application">Application</a></li>
  <li><a href="#exercises" id="toc-exercises" class="nav-link" data-scroll-target="#exercises">Exercises</a>
  <ul class="collapse">
  <li><a href="#conceptual-questions" id="toc-conceptual-questions" class="nav-link" data-scroll-target="#conceptual-questions">1. Conceptual Questions</a></li>
  <li><a href="#bayes-rule" id="toc-bayes-rule" class="nav-link" data-scroll-target="#bayes-rule">2. Bayes‚Äô Rule</a></li>
  <li><a href="#independence-assumption" id="toc-independence-assumption" class="nav-link" data-scroll-target="#independence-assumption">3. Independence Assumption</a></li>
  </ul></li>
  <li><a href="#literature" id="toc-literature" class="nav-link" data-scroll-target="#literature">Literature</a></li>
  </ul>
</nav>
</div>
<div id="quarto-margin-sidebar" class="sidebar margin-sidebar zindex-bottom">
</div>
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Bayes Optimal Decision Rule and Types of Classification Models</h1>
<p class="subtitle lead">Accompanying Notebook for my presentation in the seminar Applied Statistics, Department of Mathematics and Natural Sciences, University of Kassel</p>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<style>
#title-block-header h1.title {
  text-align: center; 
  font-size: 200%;
}
#title-block-header .subtitle {
  text-align: center; 
  font-size: 100%;
  margin-top: 1.5em;
}

h1 {
  font-size: 160%;
}
h2 {
  font-size: 130%;
}
h3 {
  font-size: 110%;
}
#quarto-toc,
nav#TOC {
  position: sticky;
  top: 0rem;
  overflow-y: auto;               
}
body, p {
  text-align: justify;
}
</style>
<p><br></p>
<p><br></p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="nostromo_coffee.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="100"></p>
</figure>
</div>
<p><span style="display: block; text-align: center; color: darkred; font-size: 140%;">in progress.</span></p>
<p><br></p>
<section id="introduction" class="level1">
<h1>Introduction</h1>
<p>This Notebook complements the presentation by</p>
<ul>
<li><p>providing the proofs discussed, and</p></li>
<li><p>implementing Gaussian Naive Bayes in R.</p></li>
</ul>
<p><br></p>
<section id="topics" class="level2">
<h2 class="anchored" data-anchor-id="topics">Topics</h2>
<ol type="1">
<li><p>Bayes Optimal Decision Rule</p></li>
<li><p>Generative vs.&nbsp;discriminative classification models</p></li>
<li><p>Introduction of Naive Bayes Classifier with Gaussian distribution as an example of a generative classification model</p></li>
</ol>
<p><br></p>
</section>
<section id="orientation-map" class="level2">
<h2 class="anchored" data-anchor-id="orientation-map">Orientation Map</h2>
<div class="cell">
<div class="cell-output-display">
<div class="grViz html-widget html-fill-item" id="htmlwidget-b8a1cd66f4ce33fdc267" style="width:100%;height:650px;"></div>
<script type="application/json" data-for="htmlwidget-b8a1cd66f4ce33fdc267">{"x":{"diagram":"digraph{\n                graph[layout = neato, splines = line]\n                node[shape = rectangle, style =\"\"]\n                \n                A[label = \"Machine Learning\", \n                          style = \"filled\", fillcolor = \"lightseagreen\",\n                          tooltip = \"Machine Learning\", \n                          pos = \"0,3!\"]\n                          \n                B[label = \"Response Type\", tooltip = \"Response Type\",\n                          style = \"filled, rounded\", fillcolor = \"lightskyblue2\",\n                          pos = \"0,2!\"]\n                          \n                C1[label = \"Regression\", tooltip = \"Regression\"\n                          color=transparent, pos = \"-2.5,1!\"]\n                          \n                C2[label = \"Classification \n y ‚àà {1, ..., c-1}\", \n                          tooltip =\"Classification\", \n                          style = \"filled, rounded\", fillcolor = \"lightskyblue2\",  \n                          pos = \"2.5,1!\"]\n\n                D1[label = \"Squared-Error Loss\", tooltip = \"Squared-Error Loss\" \n                          color = transparent, pos = \"-2.5,0!\"]\n                          \n                D2[label = \"Indicator Loss \n 1{y‚â†≈∑}\", tooltip = \"Indicator Loss\" \n                          style = \"filled, rounded\", fillcolor = \"#A79CF9\", \n                           pos = \"2.5,0!\"]\n                           \n                E[label = \"Optimal Classifier\", tooltip = \"Optimal Classifier\" \n                          style = \"filled, rounded\", fillcolor = \"#A79CF9\", \n                           pos = \"2.5,-1!\"]\n                          \n                F1[label = \"generative \n p(x,y)\", tooltip = \"generative\" style = \"filled,\n                          rounded\", fillcolor = \"#A79CF9\",  \n                          pos = \"1,-2!\"]\n                          \n                F2[label = \"discriminative \n p(y|x)\", tooltip = \"discriminative\" \n                          style = \"filled, rounded\", fillcolor = \"#A79CF9\",  \n                          pos = \"4,-2!\"]\n                          \n                G1[label = \"Naive Bayes\", tooltip = \"Naive Bayes\", \n                          style = \"filled, rounded\", fillcolor = \"#A79CF9\", \n                           pos = \"1,-3!\"]\n                          \n                H1[label = \"Linear Regression\", tooltip = \"Linear Regression\", \n                          color = transparent, pos = \"-2.5,-3!\"]\n                          \n                H2[label = \"Gaussian\", tooltip = \"Gaussian\", style = \"filled, rounded\", \n                          fillcolor = \"#A79CF9\",  pos = \"0,-4!\"]\n                          \n                H3[label = \"other distributions\", tooltip = \"other distributions\", \n                          color=transparent, pos = \"2,-4!\"]\n\n                H4[label = \"Logistic Regression\", tooltip = \" Logistic Regression\", \n                          color=transparent, pos = \"4,-3!\"]\n                \n                I1[shape = point, width = 0, height = 0, label = \"\", pos = \"-2.5,-5.5!\",                              style = invis, tooltip = \"Logit\"]\n                \n                I2[shape = point, width = 0, height = 0, label = \"\", pos = \"4,-5.5!\",                                 style = invis, tooltip = \"Logit\"]\n                \n                edge[color = black]\n                \n                A -> B [arrowhead = none, tooltip = \" \", penwidth = 2]\n                B -> C1 [arrowhead = none, tooltip = \" \"]\n                B -> C2 [arrowhead = none, tooltip = \" \", penwidth = 2]\n                C1 -> D1 [arrowhead = none, tooltip = \" \"]\n                C2 -> D2 [arrowhead = none, tooltip = \" \", penwidth = 2]\n                D1 -> H1 [arrowhead = empty, tooltip = \" \"]\n                D2 -> E [arrowhead = none, tooltip = \" \", penwidth = 2]\n                E -> F1 [arrowhead = none, tooltip = \" \", penwidth = 2]\n                E -> F2 [arrowhead = none, tooltip = \" \", penwidth = 2]\n                F1 -> G1 [tooltip = \" \", penwidth = 2]\n                F2 -> H4 [arrowhead = empty, tooltip = \" \"]\n                G1 -> H2 [arrowhead = none, tooltip = \" \", penwidth = 2]\n                G1 -> H3 [arrowhead = none, tooltip = \" \"]\n\n                \n                edge[arrowhead = none, tooltip = \"Logit\"]\n                H1 -> I1 [color = grey, tooltip = \"Logit\"]\n                I1 -> I2 [color = grey, fontcolor = grey, xlabel = \"Logit-Link\", \n                          tooltip = \"Logit\"]\n\n                edge[arrowhead = normal]\n                I2 -> H4 [arrowhead = empty, color = grey, tooltip = \"Logit\"]\n                \n}","config":{"engine":"neato","options":null}},"evals":[],"jsHooks":[]}</script>
</div>
</div>
<p><br></p>
<p>This is my own representation and reflects my learning outcomes based on the given literature and with regard to the seminar topic. It is not intended to be exhaustive. For example, there are more generative models than Naive Bayes, and the indicator loss does not necessarily lead to logistic regression in a discriminative learning context.</p>
<p><br></p>
</section>
</section>
<section id="key-concepts" class="level1">
<h1>Key Concepts</h1>
<section id="marginalization" class="level2">
<h2 class="anchored" data-anchor-id="marginalization">Marginalization</h2>
<p>For a pair of random variables <span class="math inline">(X,Y)</span>, the density <span class="math inline">f_X(x)</span> of a <em>marginal</em> variable <span class="math inline">X</span> is obtained from the <em>joint pdf</em> <span class="math inline">f_{X,Y}(x,y)</span> by integrating out the other variable:</p>
<p><span class="math display">
f_X(x)=\int f_{X,Y}(x,y) \, \mathrm{d}y.
</span></p>
<p>Thus, if the joint density is known, the information about the individual variables can be recovered (Kroese et al., 2024, p.&nbsp;427). This operation is called <em>marginalization</em>.</p>
</section>
<section id="conditional-density" class="level2">
<h2 class="anchored" data-anchor-id="conditional-density">Conditional Density</h2>
<p>Let <span class="math inline">X</span> and <span class="math inline">Y</span> be random variables with joint pdf <span class="math inline">f_{X,Y}(x,y)</span>, and assume <span class="math inline">f_X(x)&gt;0</span>. Then the <em>conditional pdf</em> of <span class="math inline">Y</span> given <span class="math inline">X=x</span> is</p>
<p><span class="math display">
f_{Y \vert X}(y \vert x)= \frac{f_{X,Y}(x,y)}{f_X(x)}
</span></p>
<p>(Kroese et al., 2024, p.&nbsp;431).</p>
</section>
<section id="conditional-expectation" class="level2">
<h2 class="anchored" data-anchor-id="conditional-expectation">Conditional Expectation</h2>
<p>In the continuous case, the <em>conditional expectation</em> of a random variable <span class="math inline">Y</span> given <span class="math inline">X=x</span> is defined as</p>
<p><span class="math display">
\mathbb{E}[Y \vert X=x]=\int y \;f_{Y \vert X}(y \vert x) \, \mathrm{d}y
</span></p>
<p>(Kroese et al., 2024, p.&nbsp;431). Replace the integral with a sum for the discrete case. ‚ÄúNote that <span class="math inline">\mathbb{E}[Y \vert X=x]</span> is a function of <span class="math inline">x</span>. The corresponding random variable is written as <span class="math inline">\mathbb{E}[Y \vert X]</span>‚Äù (Kroese et al., 2024, p.&nbsp;431).</p>
<p><br></p>
</section>
</section>
<section id="proofs" class="level1">
<h1>Proofs</h1>
<section id="tower-property" class="level2">
<h2 class="anchored" data-anchor-id="tower-property">Tower Property</h2>
<p><span class="math display">\begin{align*}
&amp;\text{Claim:} &amp;&amp;\mathbb{E}[\mathbb{E}[Y \vert X]] &amp;&amp;=\mathbb{E}[Y] \\[12pt]
&amp;\text{Proof:} &amp;&amp;\mathbb{E}[Y \vert X] &amp;&amp;= \int_{\mathbb{R}} y \, f_{Y \vert X}(y \vert x) \, \mathrm{d}y &amp;&amp;&amp; &amp;&amp;&amp; \color{transparent}{\text{xxxxxxxxxxxxxxx}} \\[4pt]
&amp; &amp;&amp; &amp;&amp;=\int_{\mathbb{R}} y \, \frac{f_{X,Y}(x,y)}{f_X(x)} \, \mathrm{d}y \\[4pt]
&amp;\Leftrightarrow  &amp;&amp;\mathbb{E}[\mathbb{E}[Y \vert X]] &amp;&amp;=\int_{\mathbb{R}} \int_{\mathbb{R}}  y \, \frac{f_{X,Y}(x,y)}{f_X(x)} \, \mathrm{d}y \, f_X(x) \, \mathrm{d}x \\[4pt]
&amp; &amp;&amp; &amp;&amp;=\int_{\mathbb{R}} \int_{\mathbb{R}} y \, f_{X,Y}(x,y) \, \mathrm{d}y \, \mathrm{d}x \\[4pt]
&amp; &amp;&amp; &amp;&amp;=\int_{\mathbb{R}} y \, \int_{\mathbb{R}} f_{X,Y} \, \mathrm{d}x \, \mathrm{d}y \\[4pt]
&amp; &amp;&amp; &amp;&amp;=\int_{\mathbb{R}} y \, f_Y(y) \, \mathrm{d}y \\[4pt]&amp; &amp;&amp; &amp;&amp;=\mathbb{E}[Y] &amp;&amp;&amp; \Box
\end{align*}</span></p>
<p><br></p>
</section>
<section id="mathbbeùüô_ymathbbpy" class="level2">
<h2 class="anchored" data-anchor-id="mathbbeùüô_ymathbbpy"><span class="math inline">\mathbb{E}[ùüô_Y]=\mathbb{P}(Y)</span></h2>
<p><span class="math inline">\bullet \ (\boldsymbol{X},Y) \text{ with joint pdf }f_{\boldsymbol{X},Y}(\boldsymbol{x},y)</span></p>
<p><span class="math inline">\bullet \ \operatorname{g}:\mathbb{R}^d \to \{0, \ldots, c-1\}</span></p>
<p><span class="math inline">\bullet \ \operatorname{Loss}(Y, \operatorname{g}(\boldsymbol{X}))=\mathbb{1}\{Y \neq \operatorname{g}(\boldsymbol{X})\}</span></p>
<p><br></p>
<p><span class="math display">
\begin{align*}
&amp;\text{Claim:} &amp;&amp;\mathbb{E}[ùüô\{Y\neq\operatorname{g}(\boldsymbol{X})\}] &amp;&amp;=\mathbb{P}(Y\neq\operatorname{g}(\boldsymbol{X})). \\[16pt]
&amp;\text{Proof:} &amp;&amp;\mathbb{E}[ùüô{\{Y\neq\operatorname{g}(\boldsymbol{X})\}}] &amp;&amp;=\int_{\mathbb{R}^d\times\{0,\ldots,c-1\}}ùüô\{y\neq\operatorname{g}(\boldsymbol{x})\} \ f_{\boldsymbol{X},Y}(\boldsymbol{x},y) \, \mathrm{d}y \, \mathrm{d}\boldsymbol{x} \\[4pt] \\[4pt]
&amp; &amp;&amp; &amp;&amp;=\int_{\mathbb{R}^d} \, \int_{\{0, \ldots, c-1\}} ùüô \{y \neq \operatorname{g}(\boldsymbol{x})\} \, f_{\boldsymbol{X},Y}(\boldsymbol{x},y)\, \mathrm{d}y\, \mathrm{d}\boldsymbol{x} \\[4pt]
&amp; &amp;&amp; &amp;&amp;=\int_{\mathbb{R}^d} \, \int_{\{y \in \{0, \ldots, c-1\}: \, y\neq\operatorname{g}(\boldsymbol{x})\}} \, f_{\boldsymbol{X},Y}(\boldsymbol{x},y)\, \mathrm{d}y\, \mathrm{d}\boldsymbol{x} \\[4pt]
&amp; &amp;&amp; &amp;&amp;=\int_{\{(\boldsymbol{x},y): \, y\neq\operatorname{g}(\boldsymbol{x})\}} \, f_{\boldsymbol{X},Y}(\boldsymbol{x},y) \, \mathrm{d}y \, \mathrm{d}\boldsymbol{x} \\[16pt]
&amp; &amp;&amp; &amp;&amp;=\mathbb{P}(Y \neq \operatorname{g}(\boldsymbol{X})) \; &amp;&amp;&amp;\Box \\[4pt]\end{align*}
</span></p>
<p><br></p>
</section>
<section id="mathbbeùüô_y-vert-xmathbbpy-vert-x" class="level2">
<h2 class="anchored" data-anchor-id="mathbbeùüô_y-vert-xmathbbpy-vert-x"><span class="math inline">\mathbb{E}[ùüô_Y \vert X]=\mathbb{P}(Y \vert X)</span></h2>
<p><span class="math inline">\bullet \ Y \text{ with condition to } \boldsymbol{X}: \; f_{Y \vert \boldsymbol{X}}(y \mid \boldsymbol{x})</span></p>
<p><span class="math inline">\bullet \ \operatorname{g}:\mathbb{R}^d \to \{0, \ldots, c-1\}</span></p>
<p><span class="math inline">\bullet \ \operatorname{Loss}(Y, \operatorname{g}(\boldsymbol{X}))=ùüô\{Y \neq \operatorname{g}(\boldsymbol{X})\}</span></p>
<p><br></p>
<p><span class="math display">
\begin{align*}
&amp;\text{Claim:} &amp;&amp;\mathbb{E}[ùüô\{Y\neq\operatorname{g}(\boldsymbol{X})\} \vert \boldsymbol{X}] &amp;&amp;=\mathbb{P}(Y\neq\operatorname{g}(\boldsymbol{X}) \vert \boldsymbol{X}=\boldsymbol{x}). \\[16pt]
&amp;\text{Proof:} &amp;&amp;\mathbb{E}[ùüô\{Y\neq\operatorname{g}(\boldsymbol{X})\} \mid \boldsymbol{X}=\boldsymbol{x}] &amp;&amp;=\int_{\{0,\ldots,c-1\}}ùüô\{y\neq\operatorname{g}(\boldsymbol{x})\} \ f_{Y \vert \boldsymbol{X}}(y \mid \boldsymbol{x}) \, \mathrm{d}y \\[4pt]
&amp; &amp;&amp; &amp;&amp;=\int_{\{y \in \{0, \ldots, c-1\}: \, y\neq\operatorname{g}(\boldsymbol{x})\}} \, f_{Y \vert \boldsymbol{X}}(y \mid \boldsymbol{x})\, \mathrm{d}y \\[16pt]
&amp; &amp;&amp; &amp;&amp;=\mathbb{P}(Y \neq \operatorname{g}(\boldsymbol{X}) \mid \boldsymbol{X}=\boldsymbol{x}) &amp;&amp;&amp; \Box
\end{align*}
</span></p>
<p><br></p>
</section>
<section id="optimal-classifier" class="level2">
<h2 class="anchored" data-anchor-id="optimal-classifier">Optimal Classifier</h2>
<p><span class="math display">
\begin{align*}
&amp;\text{Claim:} &amp;&amp;\operatorname{g}^*(\boldsymbol{x}) &amp;&amp;= \underset{y \in \{0,\ldots,c-1\}}{\operatorname{arg\,max}}\,\mathbb{P}\big(Y=y \,\mid \boldsymbol{X}=\boldsymbol{x}\big). \\[18pt]
&amp;\text{Proof:} &amp;&amp;\operatorname{Loss}(Y, \operatorname{g}(\boldsymbol{X}))  &amp;&amp;= ùüô{\{\,Y \neq \operatorname{g}(\boldsymbol{X})\,\}} \\[4pt]
&amp;\Leftrightarrow &amp;&amp; \ell(\operatorname{g})  &amp;&amp;= \mathbb{E}\big[ ùüô{\{\,Y \neq \operatorname{g}(\boldsymbol{X})\,\}} \big] \\[4pt]
&amp; &amp;&amp; &amp;&amp;= \mathbb{E} \big[\mathbb{E} \big[ùüô{\{\,Y \neq \operatorname{g}(\boldsymbol{X})\,\}} \mid \boldsymbol{X} \big] \big] \\[4pt]
&amp; &amp;&amp; &amp;&amp;=\mathbb{E}\big[P(Y \neq \operatorname{g}(\boldsymbol{X}) \mid \boldsymbol{X})\big] \\[4pt]
&amp; \overset{\color{darkgreen}{*}}{\Rightarrow} &amp;&amp;\underset{\scriptscriptstyle y \in \{0,\ldots,c-1\}}{\operatorname{arg\,min}} \ \mathbb{P}(Y \neq y \mid \boldsymbol{X}=\boldsymbol{x}) &amp;&amp;=\underset{\scriptscriptstyle y \in \{0,\ldots,c-1\}}{\operatorname{arg\,min}}\big(1-\mathbb{P}(Y = y \mid \boldsymbol{X}=\boldsymbol{x})\big) \\[4pt]
&amp; &amp;&amp; &amp;&amp;=\underset{\scriptscriptstyle y \in \{0,\ldots,c-1\}}{\operatorname{arg\,max}} \ \mathbb{P}(Y=y \mid \boldsymbol{X}=\boldsymbol{x}) \\[4pt]
&amp; &amp;&amp; &amp;&amp;=\operatorname{g}^*(\boldsymbol{x}) &amp;&amp;&amp; \Box
\end{align*}
</span></p>
<p><span class="math inline">\color{darkgreen}{\text{*}}</span> To minimize the expectation (the risk <span class="math inline">\ell(\mathrm{g})</span>), the conditional probability must be minimized pointwise.</p>
<p><br></p>
</section>
</section>
<section id="model-types" class="level1">
<h1>Model Types</h1>
<p>There are two fundamental modelling approaches to classification. Generative classification aims to model the joint density <span class="math inline">f_{\boldsymbol{X}, Y}(\boldsymbol{x}, y)</span>. From this joint distribution, the conditional density <span class="math inline">f_{Y \mid \boldsymbol{X}}(y \mid \boldsymbol{x})</span> can be obtained, which enables classification.</p>
<p>Discriminative models take a different approach. Instead of modelling the full joint distribution, they estimate directly what is needed for classification - either the conditional probability <span class="math inline">f_{Y \mid \boldsymbol{X}}(y \mid \boldsymbol{x})</span> or even only the decision boundary between classes.</p>
<section id="pros-and-cons" class="level2">
<h2 class="anchored" data-anchor-id="pros-and-cons">Pros and cons</h2>
<p>According to Murphy 2012, p.&nbsp;268-269, <span style="color: #6C4FC0;">generative and discriminative classifiers</span> have following advantages and disadvantages:</p>
<p><strong>Advantages of generative models</strong></p>
<ul>
<li><p>Generative models are often simple to train. For example, naive Bayes require only counting and averaging. In contrast, logistic regression requires solving a convex optimization problem, which is computionally more demanding.</p></li>
<li><p>Generative models estimate parameters separatly for each class density. Therefore, a new class can be added without retraining the entire model. Discriminative models must be retrained from scratch, since all parameters are interdependent.</p></li>
<li><p>Because generative models specify a full probability model for <span class="math inline">x</span>, they can deal with missing data using marginalization. Discriminative classifiers assume all components are observed, handling missing data is non-trivial.</p></li>
<li><p>Generative models can easily incorporate unlabeled data (semi-supervised learning), whereas discriminative classifiers struggle with this.</p></li>
<li><p>Generative models are symmetric in inputs and outputs, enabling inference of inputs from outputs. Discriminative models cannot be run reverse.</p></li>
</ul>
<p><strong>Advantages of discriminative models</strong></p>
<ul>
<li><p>Discriminative models allow arbitrary feature transformation such as basis expansion <span class="math inline">\phi(\boldsymbol{x})</span>. Generative models have difficulties with Feature-Preprocessing.</p></li>
<li><p>Generative models like naive Bayes require strong assumptions that are often violated, leading to overconfident posteriors near 0 and 1. Discriminative models such as logistic regression yield better probability calibration.</p></li>
</ul>
</section>
<section id="some-models-listed" class="level2">
<h2 class="anchored" data-anchor-id="some-models-listed">Some models listed</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="gen-dis-models.png" class="img-fluid figure-img"></p>
<figcaption>Murphy 2012, p.&nbsp;270</figcaption>
</figure>
</div>
<p><br></p>
</section>
</section>
<section id="classification-via-bayes-rule" class="level1">
<h1>Classification via Bayes‚Äô Rule</h1>
<p>‚ÄúFollowing standard practice in Bayesian context, instead of writing <span class="math inline">f_X(x)</span> and <span class="math inline">f_{X \vert Y}(x \mid y)</span> for the pdf of <span class="math inline">X</span> and the conditional pdf of <span class="math inline">X</span> given <span class="math inline">Y</span>, one simply writes <span class="math inline">f(x)</span> and <span class="math inline">f(x \mid y)</span>. If <span class="math inline">Y</span> is a different random variable, its pdf (at y) is thus denoted by <span class="math inline">f(y)</span>‚Äù (Kroese et al., 2024, p.&nbsp;48).</p>
<p>For a class-dependent probability, Bayes‚Äô Rule is <span class="math display">\\[18pt] f(y \mid x)= \frac{f(x,y)}{f(x)}. \\[18pt]</span></p>
<p>The joint pdf <span class="math inline">f(x,y)</span> can be expressed as <span class="math inline">f(x \mid y) \, f(y)</span>. Assume <span class="math inline">\boldsymbol{x}</span> is a feature vector. Since <span class="math inline">f(\boldsymbol{x})</span> is constant with respect to y, it follows:</p>
<p><span class="math display">
\\[18pt] f(y \mid \boldsymbol{x}) \propto f(\boldsymbol{x} \mid y) \, f(y). \\[18pt]
</span></p>
<p>According to Bayes‚Äô notation, <span class="math inline">f(y \mid x)</span> is called <em>posterior</em> probability. Further ‚Äú<span class="math inline">f(x \mid y)</span> is the <em>likelihood</em> of obtaining feature vector <span class="math inline">\boldsymbol{x}</span> of the class <span class="math inline">y</span> and <span class="math inline">f(y)</span> is the <em>prior</em> probability of class <span class="math inline">y</span>‚Äù (Kroese et al., 2024, p.&nbsp;257). If a feature vector <span class="math inline">\boldsymbol{x}</span> is to be assigned to a class <span class="math inline">\hat{y}</span>, classification is performed according to the <span style="color: #6C4FC0;">Bayes Optimal Decision Rule</span>:</p>
<p><span class="math display">
\\[18pt] \hat{y}=\arg\max_y \, f(y \mid \boldsymbol{x}), \\[18pt]
</span></p>
<p>which is the Bayesian expression of the Optimal Classifier - that is, the class maximizing the (unnormalized) posterior probability.</p>
<p><br></p>
</section>
<section id="naive-bayes" class="level1">
<h1>Naive Bayes</h1>
<p>As shown above, Bayesian classification exploits the fact that <span class="math inline">f(x)</span> is constant across all <span class="math inline">y</span>, so it can be omitted in the decision rule. Because the true density of <span class="math inline">f(y \mid \boldsymbol{x})</span> is unknown, it is approximated by a function <span class="math inline">\mathrm{g}(y \mid \boldsymbol{x})</span> from a specified class of functions <span class="math inline">\mathcal{G}</span>. The function class <span class="math inline">\mathcal{G}</span> can then be endowed with distributional assumptions: ‚ÄúIn the na√Øve Bayes method, the class of approximating functions <span class="math inline">\mathcal{G}</span> is chosen such that <span class="math inline">\mathrm{g}(\boldsymbol{x} \mid y) \;=\; \mathrm{g}(x_1 \mid y)\, \mathrm{g}(x_2 \mid y)\,\cdots\, \mathrm{g}(x_p \mid y),</span> that is, conditional on the label, all features are independent‚Äù (Kroese et al., 2024, p.&nbsp;258). Assuming a uniform prior over the classes, the factor <span class="math inline">f(y)</span> is constant across all <span class="math inline">y</span> and can also be omitted:</p>
<p><span class="math display">
\mathrm{g}(y \mid \boldsymbol{x}) \propto \prod_{j=1}^p \mathrm{g}(x_j \mid y). \\[18pt]
</span></p>
<p>Assume the approximating class <span class="math inline">\mathcal{G}</span> has a Gaussian distribution, i.e.&nbsp;<span class="math inline">(\boldsymbol{X}_j \mid y) \sim \mathcal{N}(\mu_{yj}, \ \sigma^2)</span>, <span class="math inline">y=0, \ldots, c-1</span>, <span class="math inline">j=1, \ldots, p</span>. The Gaussian pdf is:<br>
<br>
<span class="math display">
\\[18pt] f(x)=\frac{1}{\sigma\sqrt{2 \pi}} \ \exp \left({{-\frac{1}{2}\frac{(x-\mu)^2}{\sigma^2}}}\right), \\[18pt]
</span></p>
<p>insert into naive Bayes factorization:</p>
<p><span class="math display">
\\[18pt] \mathrm{g}(\boldsymbol{x}_j \mid y) = \frac{1}{\sigma\sqrt{2 \pi}} \ \exp \left({ -\frac{1}{2}\frac{(x_j-\mu_{yj})^2}{\sigma^2}} \right). \\[18pt]
</span></p>
<p>The scaling factor <span class="math inline">\frac{1}{\sqrt{2 \pi \sigma^2}}</span> does not depend on <span class="math inline">y</span> and therefore drops out in the decision rule. Thus, classification is based on comparing the unnormalized posteriors:</p>
<p><span class="math display">
\\[18pt] \mathrm{g}(y \mid \boldsymbol{\theta}, \ \boldsymbol{x}) \propto \prod_{j=1}^p  \exp \left(-\frac{1}{2}\frac{(x_j-\mu_{yj})^2}{\sigma^2} \right), \\[18pt]
</span></p>
<p>which is:</p>
<p><span class="math display">
\\[18pt] \mathrm{g}(y \mid \boldsymbol{\theta}, \ \boldsymbol{x}) \propto \exp \left(-\frac{1}{2}\sum_{j=1}^p \frac{(x_j-\mu_{yj})^2}{\sigma^2} \right). \\[18pt]
</span></p>
<p>The sum is the Euclidean distance:</p>
<p><span class="math display">
\\[18pt] \sum_{j=1}^p(x_j-\mu_{yj})^2= \|x-\mu_y\|^2, \\[18pt]
</span></p>
<p>thus:</p>
<p><span class="math display">
\\[18pt] \mathrm{g}(y \mid \boldsymbol{\theta}, \ \boldsymbol{x}) \propto \exp \left(-\frac{\|x-\mu_y\|^2}{2\sigma^2} \right), \\[18pt]
</span></p>
<p>where <span class="math inline">\boldsymbol{\theta}</span> contains the parameters <span class="math inline">\mu</span> and <span class="math inline">\sigma</span>, which have to be estimated from the data. ‚ÄúThe probability <span class="math inline">\mathrm{g}(y \mid \boldsymbol{\theta}, \ \boldsymbol{x})</span> is maximal, when <span class="math inline">\|x-\mu_y\|</span> is minimal. Thus, <span class="math inline">\hat{y}=\mathrm{arg \ min}_y\ \|\boldsymbol{x}-\boldsymbol{\mu}_y\|</span> is the classifier. That is, classify <span class="math inline">\boldsymbol{x}</span> as <span class="math inline">y</span> when <span class="math inline">\boldsymbol{\mu}_y</span> is closest to <span class="math inline">\boldsymbol{x}</span> in Euclidean distance‚Äù (Kroese et al., 2024, p.&nbsp;258).</p>
<p><br></p>
</section>
<section id="application" class="level1">
<h1>Application</h1>
<p>Implement <span style="color:#6C4FC0;">Gaussian Naive Bayes in R</span> without using any built-in model implementations.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># data handling I</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="co"># data are in wide format,</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="co"># one row = one image,</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="co"># first column contains the labels,</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="co"># labels are integers in {0,...,9},</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="co"># each image has 28x28 pixels,</span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="co"># pixels are integers in {0,...,255}.</span></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="co"># LABELS</span></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="co"># select first column, save as vector.</span></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>y_train <span class="ot">&lt;-</span> <span class="fu">as.factor</span>(train[ ,<span class="dv">1</span>])</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>y_test  <span class="ot">&lt;-</span> <span class="fu">as.factor</span>(test[ ,<span class="dv">1</span>])</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a><span class="co"># PIXELS</span></span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a><span class="co"># select all rows and columns, </span></span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a><span class="co"># except first column, save as matrix.</span></span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>X_train <span class="ot">&lt;-</span> <span class="fu">as.matrix</span>(train[ ,<span class="sc">-</span><span class="dv">1</span>])</span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a>X_test  <span class="ot">&lt;-</span> <span class="fu">as.matrix</span>(test[ ,<span class="sc">-</span><span class="dv">1</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co"># fitting model / compute parameters</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>fit_GNB <span class="ot">&lt;-</span> <span class="cf">function</span>(X, y, <span class="at">eps =</span> <span class="fl">1e-6</span>){</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>  X   <span class="ot">&lt;-</span> <span class="fu">as.matrix</span>(X)</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>  y   <span class="ot">&lt;-</span> <span class="fu">as.factor</span>(y)</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>  priors  <span class="ot">&lt;-</span> <span class="fu">table</span>(y)<span class="sc">/</span><span class="fu">length</span>(y)</span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>  means   <span class="ot">&lt;-</span> <span class="fu">rowsum</span>(X, y) <span class="sc">/</span> <span class="fu">as.numeric</span>(<span class="fu">table</span>(y))</span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>  vars    <span class="ot">&lt;-</span> (<span class="fu">rowsum</span>(X<span class="sc">^</span><span class="dv">2</span>, y)<span class="sc">/</span><span class="fu">as.numeric</span>(<span class="fu">table</span>(y))) <span class="sc">-</span> means<span class="sc">^</span><span class="dv">2</span></span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a>  vars[vars <span class="sc">&lt;</span> eps] <span class="ot">&lt;-</span> eps</span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a>  <span class="fu">list</span>(<span class="at">priors =</span> priors,</span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a>       <span class="at">means =</span> means,</span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a>       <span class="at">vars =</span> vars)</span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><br></p>
<p>In Fashion-MNIST, Gaussian Naive Bayes estimates one variance for each class-pixel combination, resulting in 10x784 distinct variances. Analogue to the previous section, <span class="math inline">\frac{1}{\sqrt{2\pi}}</span> can be omitted, because it does not depend on <span class="math inline">y</span>. Thus, the class-conditional likelihood for pixel <span class="math inline">j</span> in class <span class="math inline">y</span> is</p>
<p><span class="math display">\\[18pt] \mathrm{g}(\boldsymbol{x}_j \mid y) = \frac{1}{\sigma_{yj}} \ \exp \left({ -\frac{(x_j-\mu_{yj})^2}{2\sigma_{yj}^2}} \right). \\[18pt]</span></p>
<p>The corresponding posterior is</p>
<p><span class="math display">\mathrm{g}(y \mid \boldsymbol{\theta}, \ \boldsymbol{x}) \propto \mathrm{g}(y)  \prod_{j=1}^{784} \ \left( \frac{1}{\sigma_{yj}} \ \exp \left(-\frac{(x_j-\mu_{yj})^2}{2\sigma_{yj}^2} \right) \right). \\[18pt]</span></p>
<p>To avoid <em>numerical underflow</em> (Murphy, 2012, p.&nbsp;86), the log is taken:</p>
<p><span class="math display">\\[18pt] \log \, \mathrm{g}(y \mid \boldsymbol{\theta}, \ \boldsymbol{x}) \propto \log\mathrm{g}(y) +  \sum_{j=1}^{784} \left( \, \log \left( \frac{1}{\sigma_{yj}}\right) \ -\frac{(x_j-\mu_{yj})^2}{2\sigma_{yj}^2} \right) \\[18pt] = \log\mathrm{g}(y) + \sum_{j=1}^{784} \, \left( -\log \left(\sigma_{yj} \right) -\frac{(x_j-\mu_{yj})^2}{2\sigma_{yj}^2} \right). \\[18pt]</span></p>
<p>Implementation in R:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co"># prediction function</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>pred_GNB <span class="ot">&lt;-</span> <span class="cf">function</span>(model, X){</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>  X <span class="ot">&lt;-</span> <span class="fu">as.matrix</span>(X)</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>  n <span class="ot">&lt;-</span> <span class="fu">nrow</span>(X)</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>  classes <span class="ot">&lt;-</span> <span class="fu">names</span>(model<span class="sc">$</span>priors)</span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>  K       <span class="ot">&lt;-</span> <span class="fu">length</span>(classes)</span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a>  log_post <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="cn">NA</span>, n, K)</span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> (k <span class="cf">in</span> <span class="fu">seq_len</span>(K)){</span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a>    mu <span class="ot">&lt;-</span> model<span class="sc">$</span>means[k, ]</span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a>    va <span class="ot">&lt;-</span> model<span class="sc">$</span>vars[k,]</span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a>    ll <span class="ot">&lt;-</span> <span class="fu">rowSums</span>(<span class="sc">-</span><span class="fl">0.5</span> <span class="sc">*</span> <span class="fu">log</span>(va) <span class="sc">-</span> (<span class="fu">sweep</span>(X, <span class="dv">2</span>, mu, <span class="st">"-"</span>)<span class="sc">^</span><span class="dv">2</span>) <span class="sc">/</span> (<span class="dv">2</span> <span class="sc">*</span> va))</span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a>    log_post[ ,k] <span class="ot">&lt;-</span> ll <span class="sc">+</span> <span class="fu">log</span>(<span class="fu">as.numeric</span>(model<span class="sc">$</span>priors[k]))</span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb3-20"><a href="#cb3-20" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb3-21"><a href="#cb3-21" aria-hidden="true" tabindex="-1"></a>  idx <span class="ot">&lt;-</span> <span class="fu">max.col</span>(log_post, <span class="at">ties.method =</span> <span class="st">"first"</span>)</span>
<span id="cb3-22"><a href="#cb3-22" aria-hidden="true" tabindex="-1"></a>  <span class="fu">factor</span>(classes[idx], <span class="at">levels =</span> classes)</span>
<span id="cb3-23"><a href="#cb3-23" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><span class="math inline">\text{accuracy}_{y}=\frac{tp_j+tn_j}{n}</span></p>
<p>(Kroese et al., 2024, p.&nbsp;254)</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="co"># accuracy</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>model_GNB   <span class="ot">&lt;-</span> <span class="fu">fit_GNB</span>(X_train, y_train)</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>pred_class  <span class="ot">&lt;-</span> <span class="fu">pred_GNB</span>(model_GNB, X_test)</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(pred_class <span class="sc">==</span> y_test)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.1161</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="co"># accuracy per class</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>classes <span class="ot">&lt;-</span> <span class="fu">levels</span>(y_test)</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>accuracy_pc <span class="ot">&lt;-</span> <span class="fu">sapply</span>(classes, <span class="cf">function</span>(cl){</span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>  idx <span class="ot">&lt;-</span> <span class="fu">which</span>(y_test <span class="sc">==</span> cl)</span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mean</span>(pred_class[idx] <span class="sc">==</span> cl)</span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a>accuracy_pc</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>    0     1     2     3     4     5     6     7     8     9 
0.082 0.000 0.000 0.017 0.000 0.000 0.078 0.000 0.938 0.046 </code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="co"># plot first image.</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>plot_image <span class="ot">&lt;-</span> <span class="cf">function</span>(row){</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>  pxmat <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="fu">as.numeric</span>(row), <span class="at">nrow =</span> <span class="dv">28</span>, <span class="at">byrow =</span> T)</span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>  pxmat <span class="ot">&lt;-</span> <span class="fu">t</span>(<span class="fu">apply</span>(pxmat, <span class="dv">2</span>, rev))</span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">image</span>(pxmat, <span class="at">col =</span> <span class="fu">gray.colors</span>(<span class="dv">255</span>), <span class="at">axes =</span> F, <span class="at">asp =</span><span class="dv">1</span>)</span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a><span class="fu">plot_image</span>(train[<span class="dv">1</span>, <span class="sc">-</span><span class="dv">1</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="GNB_files/figure-html/unnamed-chunk-10-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="co"># controll label:</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>train[<span class="dv">1</span>, <span class="dv">1</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 2</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(viridis)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="co"># pixel values are not independent </span></span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a><span class="co"># plot heatmaps</span></span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>plot_avg_im <span class="ot">&lt;-</span> <span class="cf">function</span>(row){</span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a>  pxmat <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="fu">as.numeric</span>(row), <span class="at">nrow =</span> <span class="dv">28</span>, <span class="at">byrow =</span> T)</span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a>  pxmat <span class="ot">&lt;-</span> <span class="fu">t</span>(<span class="fu">apply</span>(pxmat, <span class="dv">2</span>, rev))</span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">image</span>(pxmat, <span class="at">col =</span> <span class="fu">viridis</span>(<span class="dv">255</span>), <span class="at">axes =</span> T, <span class="at">asp =</span><span class="dv">1</span>)</span>
<span id="cb12-11"><a href="#cb12-11" aria-hidden="true" tabindex="-1"></a>} </span>
<span id="cb12-12"><a href="#cb12-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-13"><a href="#cb12-13" aria-hidden="true" tabindex="-1"></a><span class="co">#heatmap pullover</span></span>
<span id="cb12-14"><a href="#cb12-14" aria-hidden="true" tabindex="-1"></a>avg_pul     <span class="ot">&lt;-</span> train <span class="sc">%&gt;%</span> <span class="fu">filter</span>(label <span class="sc">==</span> <span class="dv">2</span>) <span class="sc">%&gt;%</span> <span class="fu">select</span>(<span class="sc">-</span>label) <span class="sc">%&gt;%</span> <span class="fu">colMeans</span>()</span>
<span id="cb12-15"><a href="#cb12-15" aria-hidden="true" tabindex="-1"></a>avg_pul_df  <span class="ot">&lt;-</span> <span class="fu">as.data.frame</span>(<span class="fu">t</span>(avg_pul))</span>
<span id="cb12-16"><a href="#cb12-16" aria-hidden="true" tabindex="-1"></a><span class="fu">plot_avg_im</span>(avg_pul_df) </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="GNB_files/figure-html/unnamed-chunk-13-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="co"># heatmap bag</span></span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a><span class="co">#avg_bag     &lt;- train %&gt;% filter(label == 8) %&gt;% select(-label) %&gt;% colMeans()</span></span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a><span class="co">#avg_bag_df  &lt;- as.data.frame(t(avg_bag))</span></span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a><span class="co">#plot_avg_im(avg_bag_df)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="co"># pixel values are not gaussian distributed</span></span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a><span class="co"># qq-plot</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><br>
</p>
<p><br></p>
<p><span style="display: block; text-align: center; color: darkred; font-size: 140%;"><strong>‚Ä¶</strong></span></p>
<p><br></p>
</section>
<section id="exercises" class="level1">
<h1>Exercises</h1>
<section id="conceptual-questions" class="level2">
<h2 class="anchored" data-anchor-id="conceptual-questions">1. Conceptual Questions</h2>
<p>a) Distinguish between <em>probability</em> and <em>likelihood</em>.</p>
<p>b) What is the core difference between <em>generative</em> and <em>discriminative</em> models?</p>
</section>
<section id="bayes-rule" class="level2">
<h2 class="anchored" data-anchor-id="bayes-rule">2. Bayes‚Äô Rule</h2>
<p>Given the expression:</p>
<p><span class="math inline">f(y \mid \boldsymbol{x}) \propto f(\boldsymbol{x} \mid y) \, f(y)</span></p>
<p>explain the meaning of</p>
<ul>
<li><p>the likelihood term</p></li>
<li><p>the prior</p></li>
<li><p>the posterior</p></li>
</ul>
</section>
<section id="independence-assumption" class="level2">
<h2 class="anchored" data-anchor-id="independence-assumption">3. Independence Assumption</h2>
<p>Naive Bayes assumes:</p>
<p><span class="math inline">\mathrm{g}(\boldsymbol{x} \mid y) = \prod_{j=1}^p \mathrm{g}(x_j \mid y)</span></p>
<p>Explain what this assumption means.</p>
<p><br></p>
</section>
</section>
<section id="literature" class="level1">
<h1>Literature</h1>
<p><a href="https://people.smp.uq.edu.au/DirkKroese/DSML/DSML.pdf">D.P. Kroese, Z.I. Botev, T. Taimre, R. Vaisman: Data Science and Machine Learning - Mathematical and Statistical Methods. Chapman and Hall/CRC, 2024.</a></p>
<p>K. P. Murphy. Machine learning: a probabilistic perspective. MIT press, 2012.</p>
<p><br></p>
<p><br></p>
<hr>
<div style="text-align: center; font-size: 90%; color: grey">
Jascha Kottner | 2025
</div>
</section>

</main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "Óßã";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
</div> <!-- /content -->




</body></html>